{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "005cdf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import normalize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868a08e3",
   "metadata": {},
   "source": [
    "## Question1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bdd8a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank(G, d = 0.85, max_iter = 100):\n",
    "    # Parameters:\n",
    "    #     G is the input graph \n",
    "    #     d is the dampling factor\n",
    "    #     max_iter is the maximum iterations \n",
    "    # Return:\n",
    "    #     nodes' pageranks.\n",
    "    \n",
    "    # if not directed, transform it to directed graph\n",
    "    G = G.to_directed()\n",
    "    N = G.number_of_nodes()\n",
    "    \n",
    "    # the order of nodes\n",
    "    node_list = sorted(G.nodes)\n",
    "    \n",
    "    # normalize graph matrix by columns\n",
    "    A = nx.to_numpy_matrix(G, nodelist=node_list)\n",
    "    A = np.array(A)\n",
    "    A_normalized = normalize(A, axis=0, norm='l1')\n",
    "    \n",
    "    # calculate transition matrix and initial vector\n",
    "    v = np.ones(N) / N\n",
    "    v_0 = v\n",
    "\n",
    "    # iterate \n",
    "    for i in range(max_iter):\n",
    "        v_curr = v\n",
    "        v = ((1 - d) * v_0 + d * A_normalized @ v_curr)\n",
    "        # check convergence\n",
    "        err = sum(abs(v[n] - v_curr[n]) for n in range(v.shape[0]))\n",
    "        # check if converge\n",
    "        if err < N * 1.0e-6:\n",
    "            return dict(zip(node_list, v))\n",
    "        \n",
    "    raise Exception(\"PageRank didn't converge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4935e32e",
   "metadata": {},
   "source": [
    "# Question2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82936b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open file and get edgelist\n",
    "f_hollins = open(\"hollins/hollins.dat\", \"r\")\n",
    "data_hollins = f_hollins.readlines()\n",
    "edgelist_hollins = pd.DataFrame(columns=['source', 'target'])\n",
    "link_hollins = data_hollins[1:6013]\n",
    "\n",
    "for edge in data_hollins[6013:]:\n",
    "    edge = edge.split(' ')\n",
    "    edge[0] = int(edge[0])\n",
    "    edge[1] = int(edge[1])\n",
    "    edgelist_hollins.loc[len(edgelist_hollins.index)] = [edge[0], edge[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "931a56d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate graph\n",
    "G_hollin = nx.from_pandas_edgelist(edgelist_hollins,\n",
    "                                   source='source',\n",
    "                                   target='target', \n",
    "                                   edge_attr=None, \n",
    "                                   create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "205183e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01658081465244013\n",
      "0.020209640931177636\n"
     ]
    }
   ],
   "source": [
    "# run pagerank function and compare to built-in function in networkx\n",
    "pagerank_hollins = pagerank(G_hollin)\n",
    "pr = nx.pagerank(G_hollin, alpha=0.85)\n",
    "print(max(pagerank_hollins.values()))\n",
    "print(max(pr.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae910e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file\n",
    "with open('p1.txt', 'w') as file:\n",
    "    for key in pagerank_hollins:\n",
    "        file.write(str(key))\n",
    "        file.write('\\t')\n",
    "        file.write(str(pagerank_hollins[key]))\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbaa0c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pages with the five highest Pagerank valuse are\n",
      "\n",
      "622 http://www.hollins.edu/campuslife/clubs/elective.htm \n",
      "\n",
      "2 http://www.hollins.edu/ \n",
      "\n",
      "1824 http://www1.hollins.edu/registrar/schedule_of_classes.htm \n",
      "\n",
      "2995 http://www1.hollins.edu/registrar/How%20to%20Calculate%20your%20GPA.doc \n",
      "\n",
      "431 http://www.hollins.edu/cgi-bin/sugform1.cgi \n",
      "\n",
      "pages with the five lowest Pagerank valuse are\n",
      "\n",
      "4 http://www1.hollins.edu/Docs/Forms/GetForms.htm \n",
      "\n",
      "68 http://www.hollins.edu/academics/library/services/acq.htm \n",
      "\n",
      "74 http://www.hollins.edu/admissions/ugradadm/facts/facts.htm \n",
      "\n",
      "92 http://www1.hollins.edu/registrar/registrar.htm \n",
      "\n",
      "108 http://www1.hollins.edu/Registrar/Final%202004-05%20calendar.pdf \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get 5 highest and five lowest values and their indices\n",
    "index_5high = sorted(pagerank_hollins, key=pagerank_hollins.get, reverse=True)[:5]\n",
    "index_5low = sorted(pagerank_hollins, key=pagerank_hollins.get, reverse=False)[:5]\n",
    "\n",
    "print(\"pages with the five highest Pagerank valuse are\\n\")\n",
    "for n in index_5high:\n",
    "    print(link_hollins[n])\n",
    "\n",
    "print(\"pages with the five lowest Pagerank valuse are\\n\")\n",
    "for n in index_5low:\n",
    "    print(link_hollins[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fb6f6e",
   "metadata": {},
   "source": [
    "# Question3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "483675b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_blogs = open(\"blogs/blogs.dat\", \"r\")\n",
    "data_blogs = f_blogs.readlines()\n",
    "rowlabels_blogs = data_blogs[4:1494]\n",
    "collabels_blogs = data_blogs[1495:2985]\n",
    "edgelist_blogs = data_blogs[2986:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fd1f32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_blog = nx.Graph()\n",
    "for n, value in enumerate(rowlabels_blogs, 1):\n",
    "    G_blog.add_node(n, name = value)\n",
    "\n",
    "for edge in edgelist_blogs:\n",
    "    edge = edge.strip()\n",
    "    edge = edge.split(' ')\n",
    "    if edge[0] == '!':\n",
    "        break\n",
    "    edge[0] = int(edge[0])\n",
    "    edge[1] = int(edge[1])\n",
    "    edge[2] = int(edge[2])\n",
    "    if edge[2] == 1:\n",
    "        G_blog.add_edge(edge[0], edge[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "902d240a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010203989160468711\n",
      "0.012034313739825829\n"
     ]
    }
   ],
   "source": [
    "pagerank_blog = pagerank(G_blog)\n",
    "pr_blog = nx.pagerank(G_blog, alpha=0.85)\n",
    "print(max(pagerank_blog.values()))\n",
    "print(max(pr_blog.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e59c0363",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('p2.txt', 'w') as file:\n",
    "    for key in pagerank_blog:\n",
    "        file.write(str(key))\n",
    "        file.write('\\t')\n",
    "        file.write(str(pagerank_blog[key]))\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75184cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pages with the five highest Pagerank valuse are\n",
      "\n",
      "\"blogsforbu\"\n",
      "\n",
      "\"dailykosc\"\n",
      "\n",
      "\"drudgerepo\"\n",
      "\n",
      "\"instapundi\"\n",
      "\n",
      "\"talkingpoi\"\n",
      "\n",
      "pages with the five lowest Pagerank valuse are\n",
      "\n",
      "\"40ozblogb\"\n",
      "\n",
      "\"4linatblo\"\n",
      "\n",
      "\"americandr\"\n",
      "\n",
      "\"asiannati\"\n",
      "\n",
      "\"asiegeofhe\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index_5high = sorted(pagerank_blog, key=pagerank_blog.get, reverse=True)[:5]\n",
    "index_5low = sorted(pagerank_blog, key=pagerank_blog.get, reverse=False)[:5]\n",
    "\n",
    "print(\"pages with the five highest Pagerank valuse are\\n\")\n",
    "for n in index_5high:\n",
    "    print(G_blog.nodes[n]['name'])\n",
    "\n",
    "print(\"pages with the five lowest Pagerank valuse are\\n\")\n",
    "for n in index_5low:\n",
    "    print(G_blog.nodes[n]['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338f4422",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7590941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def personalized_pagerank(G, d = 0.85, max_iter = 100, personalized = None):\n",
    "    # Parameters:\n",
    "    #     G is the input graph \n",
    "    #     d is the dampling factor\n",
    "    #     max_iter is the maximum iterations \n",
    "    #     personalized is the index of source\n",
    "    # Return:\n",
    "    #     nodes' pageranks.\n",
    "    \n",
    "    # if not directed, transform it to directed graph\n",
    "    G = G.to_directed()\n",
    "    N = G.number_of_nodes()\n",
    "    \n",
    "    # the order of nodes\n",
    "    node_list = sorted(G.nodes)\n",
    "    \n",
    "    # normalize graph matrix by columns\n",
    "    A = nx.to_numpy_matrix(G, nodelist=node_list)\n",
    "    A = np.array(A)\n",
    "    A_normalized = normalize(A, axis=0, norm='l1')\n",
    "    \n",
    "    # calculate transition matrix and initial vector\n",
    "    if personalized == None:\n",
    "        v = np.ones(N) / N\n",
    "    else:\n",
    "        v = np.zeros(N)/ N\n",
    "        v[personalized] = 1\n",
    "\n",
    "    v_0 = v\n",
    "\n",
    "    # iterate \n",
    "    for i in range(max_iter):\n",
    "        v_curr = v\n",
    "        v = ((1 - d) * v_0 + d * A_normalized @ v_curr)\n",
    "        # check convergence\n",
    "        err = sum(abs(v[n] - v_curr[n]) for n in range(v.shape[0]))\n",
    "        # check if converge\n",
    "        if err < N * 1.0e-6:\n",
    "            return dict(zip(node_list, v))\n",
    "        \n",
    "#     raise Exception(\"PageRank didn't converge\")\n",
    "    return dict(zip(node_list, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7aec0080",
   "metadata": {},
   "outputs": [],
   "source": [
    "bloglist = ['\"dailykosc\"', \n",
    "            '\"atriosblo\"', \n",
    "            '\"wonkettec\"', \n",
    "            '\"talkleftc\"', \n",
    "            '\"juancolec\"', \n",
    "            '\"powerlineb\"',\n",
    "            '\"realclearp\"',\n",
    "            '\"blogsforbu\"',\n",
    "            '\"instapundi\"',\n",
    "            '\"michellema\"']\n",
    "dataframe_blog = pd.DataFrame(columns=bloglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d13ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for blog in bloglist:\n",
    "    index = rowlabels_blogs.index(blog+'\\n')\n",
    "    pagerank_blog = personalized_pagerank(G_blog, d = 0.9, max_iter=20, personalized=index)\n",
    "    dataframe_blog[blog] = list(pagerank_blog.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da356b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_blog.to_csv('p3.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c7cc83",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8d10f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_liberal = dict(list(pagerank_blog.items())[0:757])\n",
    "dict_conservative = dict(list(pagerank_blog.items())[757:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adc806bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24710074531422646\n",
      "0.7528992546857731\n"
     ]
    }
   ],
   "source": [
    "print(sum(dict_liberal.values()))\n",
    "print(sum(dict_conservative.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c35d246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
