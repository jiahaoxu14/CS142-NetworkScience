{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13093d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 14:06:38.646010: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-20 14:06:41.365841: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from gensim.models import Word2Vec\n",
    "import stellargraph as sg\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.data import BiasedRandomWalk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, confusion_matrix, classification_report\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da5ce41",
   "metadata": {},
   "source": [
    "# Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae3b5884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def DSD_calculator(adjacency, walk_length, restart_p):\n",
    "#     \"\"\"\n",
    "#     adjacency - adjacency matrix represented as a numpy array\n",
    "#                 assumes graph is fully connected.\n",
    "#     walk_length - the length of random walks used to calculate DSD\n",
    "#                   if walk_length = -1, then calculate DSD at convergence\n",
    "#     restart_p - the restart probability\n",
    "#         if p = 0, then it's a traditional random walk\n",
    "#     returns DSD matrix represented as a numpy array\n",
    "#     \"\"\"\n",
    "#     adjacency = np.asmatrix(adjacency)\n",
    "#     n = adjacency.shape[0]\n",
    "#     degree = adjacency.sum(axis=1)\n",
    "#     p = adjacency / degree\n",
    "#     if walk_length >= 0:\n",
    "#         c = np.eye(n)\n",
    "#         for i in range(walk_length):\n",
    "#             c = (1 - restart_p) * np.dot(c, p) + restart_p * np.eye(n)\n",
    "#         return squareform(pdist(c,metric='cityblock'))\n",
    "#     else:\n",
    "#         pi = degree / degree.sum()\n",
    "#         return squareform(pdist(inv(np.eye(n) - p - pi.T),metric='cityblock'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2b4a107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DSD_calculator(adjacency, walk_length, restart_p):\n",
    "    \"\"\"\n",
    "    adjacency - adjacency matrix represented as a numpy array\n",
    "                assumes graph is fully connected.\n",
    "    walk_length - the length of random walks used to calculate DSD\n",
    "                  if walk_length = -1, then calculate DSD at convergence\n",
    "    restart_p - the restart probability\n",
    "        if p = 0, then it's a traditional random walk\n",
    "    returns DSD matrix represented as a numpy array\n",
    "    \"\"\"\n",
    "    adjacency = np.asmatrix(adjacency)\n",
    "    n = adjacency.shape[0]\n",
    "    degree = adjacency.sum(axis=1)\n",
    "    p = adjacency / degree\n",
    "    if walk_length >= 0:\n",
    "        c = np.eye(n)\n",
    "        for i in range(walk_length):\n",
    "            c = (1 - restart_p) * np.dot(c, p) + restart_p * np.eye(n)\n",
    "        return squareform(pdist(c,metric='cityblock'))\n",
    "    else:\n",
    "        pi = degree / degree.sum()\n",
    "        return squareform(pdist(inv(np.eye(n) - p - pi.T),metric='cityblock'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207606da",
   "metadata": {},
   "source": [
    "# Load Dataset & Construct Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b8da418",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df = pd.read_csv(\"data/git_web_ml/musae_git_edges.csv\")\n",
    "nodes_df = pd.read_csv(\"data/git_web_ml/musae_git_target.csv\")\n",
    "# G_github = nx.from_pandas_edgelist(edges_df, source=\"id_1\", target='id_2')\n",
    "# print('-----------------------')\n",
    "# print('Original Graph:')\n",
    "# print(G_github)\n",
    "# # print(nx.info(G_github))\n",
    "\n",
    "# sample_num = 5000\n",
    "# sample_nodes = random.choices(list(G_github.nodes()), k=sample_num)\n",
    "# G = G_github.subgraph(sample_nodes)\n",
    "# print('-----------------------')\n",
    "# print('Picked graph with 3000 nodes:')\n",
    "# print(G)\n",
    "# # print(nx.info(G))\n",
    "# largest_cc = max(nx.connected_components(G), key=len)\n",
    "# G = G.subgraph(largest_cc)\n",
    "# print('-----------------------')\n",
    "# print('Fully Connected smaller graph:')\n",
    "# print(G)\n",
    "# # print(nx.info(G))\n",
    "# G_github = G\n",
    "# # print(G_github.nodes())\n",
    "# G = StellarGraph.from_networkx(G_github)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91dd0da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 6069 nodes and 16162 edges\n"
     ]
    }
   ],
   "source": [
    "G = pickle.load(open('graph.pickle10k', 'rb'))\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "490a4735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate DSD\n",
    "# edges = nx.to_numpy_array(G_github)\n",
    "edges = nx.to_numpy_array(G)\n",
    "DSD = DSD_calculator(edges, 20, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82004210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6069\n"
     ]
    }
   ],
   "source": [
    "test = DSD\n",
    "rows = len(DSD)\n",
    "columns = len(DSD[0])\n",
    "for i in range(rows):\n",
    "    for j in range(columns):\n",
    "        if DSD[i][j] == 0:\n",
    "            test[i][j] = DSD[i][j]\n",
    "        else:\n",
    "            test[i][j] = 1.0 / DSD[i][j]\n",
    "\n",
    "print(len(test))\n",
    "node_list = list(G.nodes())\n",
    "nodes_dftest = nodes_df\n",
    "source_list = []\n",
    "target_list = []\n",
    "weight_list = []\n",
    "\n",
    "for edges in G.edges():\n",
    "    node1= edges[0]\n",
    "    node2 = edges[1]\n",
    "    index1 = node_list.index(node1)\n",
    "    index2 = node_list.index(node2)\n",
    "    weight = test[index1][index2]\n",
    "    source_list.append(node1)\n",
    "    target_list.append(node2)\n",
    "    weight_list.append(weight)\n",
    "    \n",
    "weighted_edges = pd.DataFrame(source_list, columns=['source'])\n",
    "weighted_edges['target'] = target_list\n",
    "weighted_edges['weight'] = weight_list\n",
    "G = StellarGraph(edges=weighted_edges)\n",
    "# print(G.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91ef37ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id          name  ml_target\n",
      "0   0        Eiryyy          0\n",
      "1   1    shawflying          0\n",
      "2   2   JpMCarrilho          1\n",
      "3   3     SuhwanCha          0\n",
      "4   4  sunilangadi2          1\n"
     ]
    }
   ],
   "source": [
    "print(nodes_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0011fd91",
   "metadata": {},
   "source": [
    "# Random Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c01341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rw = BiasedRandomWalk(G)\n",
    "\n",
    "walks = rw.run(\n",
    "    nodes=G.nodes(),  # root nodes\n",
    "    length=80,  # maximum length of a random walk\n",
    "    n=10,  # number of random walks per root node\n",
    "    p=0.5,  # Defines (unormalised) probability, 1/p, of returning to source node\n",
    "    q=2,  # Defines (unormalised) probability, 1/q, for moving away from source node\n",
    "    weighted=True,  # for weighted random walks\n",
    "    seed=42,  # random seed fixed for reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "379fb162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 26124, 18937, 30524, 22321, 35006, 22321, 35372, 22321, 2806, 22321, 3647, 22321, 8065, 27803, 25811, 27803, 25908, 8458, 22650, 8458, 13284, 24843, 13284, 19789, 33045, 19789, 13284, 32647, 31944, 32647, 31944, 32647, 31944, 32647, 31944, 32647, 31944, 32647, 31944, 32647, 21957, 32647, 21957, 18507, 36099, 37087, 97, 37087, 21957, 18507, 32960, 18507, 21148, 28449, 6631, 28449, 10416, 35633, 31380, 35633, 6645, 9168, 29755, 37441, 29755, 37441, 33740, 27803, 7756, 23243, 7756, 27803, 23051, 18014, 27803, 34942, 27803, 10178, 18163]\n"
     ]
    }
   ],
   "source": [
    "print(walks[110])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6cf9f6",
   "metadata": {},
   "source": [
    "# Node Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d9ba107",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_walks = [[str(n) for n in walk] for walk in walks]\n",
    "\n",
    "model = Word2Vec(str_walks, vector_size = 16, window=10, min_count=1, sg=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65f5c366",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_df = (\n",
    "    pd.DataFrame(\n",
    "        [model.wv.get_vector(str(n)) for n in G.nodes()],\n",
    "        index = G.nodes()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38dac50f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2         3         4         5         6  \\\n",
      "5      0.023817  0.047018 -0.386038  0.468563 -0.300095 -0.366555 -0.184568   \n",
      "6     -0.488567  0.098497 -0.109907  0.565695 -0.331591 -0.374777  0.051145   \n",
      "32774 -0.574875 -1.275952 -0.901271  0.541054  0.520959  0.645740 -0.291264   \n",
      "32781  0.650406 -0.411459  0.153719  1.628315 -1.328040  0.319690  0.419854   \n",
      "32782  0.238292 -0.124377 -0.495786  0.052395 -0.327776  0.152868 -0.395207   \n",
      "\n",
      "              7         8         9        10        11        12        13  \\\n",
      "5      0.471268  0.035068 -0.229809  0.497745  0.114748 -0.299116  0.120563   \n",
      "6      0.830111  0.362442  0.145871  0.566032  0.879432 -0.489558  0.526538   \n",
      "32774  0.339795  1.656167  0.067100 -0.069274  0.610459 -0.252049 -1.055325   \n",
      "32781 -1.185130  0.537332 -0.487745 -0.607852  0.311871 -0.062573 -0.240611   \n",
      "32782  0.520561 -0.313204 -0.763758  0.388737  0.073375 -0.688577  0.196944   \n",
      "\n",
      "             14        15  ml_target  \n",
      "5      0.767169  0.179072          0  \n",
      "6      1.326391 -0.383915          0  \n",
      "32774  0.924569  0.889363          0  \n",
      "32781  2.437152  0.997891          0  \n",
      "32782  0.529465 -0.541426          0  \n"
     ]
    }
   ],
   "source": [
    "test = emb_df.merge(\n",
    "    nodes_df[['id', 'ml_target']].set_index('id'),\n",
    "    left_index = True,\n",
    "    right_index = True\n",
    ")\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8deb72a",
   "metadata": {},
   "source": [
    "# Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89a04392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8330587589236683\n",
      "0.8325096101043383\n",
      "0.8330587589236683\n",
      "0.8319604612850082\n",
      "0.8319604612850082\n",
      "0.8330587589236683\n",
      "0.8330587589236683\n",
      "0.8330587589236683\n",
      "0.8319604612850082\n",
      "0.8325096101043383\n",
      "[0.8330587589236683, 0.8325096101043383, 0.8330587589236683, 0.8319604612850082, 0.8319604612850082, 0.8330587589236683, 0.8330587589236683, 0.8330587589236683, 0.8319604612850082, 0.8325096101043383]\n"
     ]
    }
   ],
   "source": [
    "x = emb_df.values\n",
    "y = test['ml_target'].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, \n",
    "    y,\n",
    "    test_size = 0.7\n",
    ")\n",
    "\n",
    "score_list = []\n",
    "\n",
    "for x in range(10):\n",
    "    # GBC classifier\n",
    "    clf = GradientBoostingClassifier(random_state=x)\n",
    "\n",
    "    # train the model\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    # evaluate Classifier\n",
    "    print(clf.score(x_test, y_test))\n",
    "    score_list.append(clf.score(x_test, y_test))\n",
    "\n",
    "# # GBC classifier\n",
    "# clf = GradientBoostingClassifier()\n",
    "\n",
    "# # train the model\n",
    "# clf.fit(x_train, y_train)\n",
    "\n",
    "# # evaluate Classifier\n",
    "# print(clf.score(x_test, y_test))\n",
    "print(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66661e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DSD_calculator(adjacency, walk_length, restart_p):\n",
    "    \"\"\"\n",
    "    adjacency - adjacency matrix represented as a numpy array\n",
    "                assumes graph is fully connected.\n",
    "    walk_length - the length of random walks used to calculate DSD\n",
    "                  if walk_length = -1, then calculate DSD at convergence\n",
    "    restart_p - the restart probability\n",
    "        if p = 0, then it's a traditional random walk\n",
    "    returns DSD matrix represented as a numpy array\n",
    "    \"\"\"\n",
    "    adjacency = np.asmatrix(adjacency)\n",
    "    n = adjacency.shape[0]\n",
    "    degree = adjacency.sum(axis=1)\n",
    "    p = adjacency / degree\n",
    "    if walk_length >= 0:\n",
    "        c = np.eye(n)\n",
    "        for i in range(walk_length):\n",
    "            c = (1 - restart_p) * np.dot(c, p) + restart_p * np.eye(n)\n",
    "        return squareform(pdist(c,metric='cityblock'))\n",
    "    else:\n",
    "        pi = degree / degree.sum()\n",
    "        return squareform(pdist(inv(np.eye(n) - p - pi.T),metric='cityblock'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1aed9ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 3. 8.]\n",
      " [3. 0. 9.]\n",
      " [8. 9. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0,2,3], [1,0,3], [3,4,0]])\n",
    "dist_matrix = pdist(X, metric = 'cityblock')\n",
    "# dist_matrix = pdist(X)\n",
    "# print(dist_matrix)\n",
    "print(squareform(dist_matrix))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
